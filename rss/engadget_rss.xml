<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:ss="http://contenthub.aol.com/slideshow/"><channel><title><![CDATA[Engadget is a web magazine with obsessive daily coverage of everything new in gadgets and consumer electronics]]></title><link/> https://www.engadget.com/ <description><![CDATA[Engadget is a web magazine with obsessive daily coverage of everything new in gadgets and consumer electronics]]></description><language> en-US</language><copyright>版权所有雅虎 2024</copyright><pubDate> Tue, 14 May 2024 19:52:59 +0000</pubDate><generator>雅虎 http://yahoo.com </generator><item><title><![CDATA[Animal Well speedrunners are already beating the game in under five minutes]]></title><description type="html"><![CDATA[<p> <a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/youtuber-dunkeys-publishing-company-is-releasing-its-first-game-on-may-9-152519368.html"><em>《动物井》</em></a>是最热门的<a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/gaming/">游戏</a>之一。上<a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1" class="no-affiliate-link" href="https://www.metacritic.com/game/animal-well/" data-original-link="https://www.metacritic.com/game/animal-well/">周四</a>发布后，它迅速登上了<a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/the-rogue-prince-of-persia-is-delayed-because-hades-ii-is-a-juggernaut-144229150.html">Steam 畅销书排行榜的榜首</a>。</p><p>虽然大多数玩家在<a data-i13n="cpos:5;pos:1" href="https://howlongtobeat.com/game/109108">四到六个小时</a>内完成主线故事，但很快，速通玩家就想出了如何冲破独立开发者比利·巴索的怪异迷宫。 YouTuber 已经发布了不到五分钟的视频，any% 记录（即没有任何限制的最佳记录时间）正在被一次又一次地打破。</p><span id="end-legacy-contents"></span><p> <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:6;pos:1" class="no-affiliate-link" href="https://www.youtube.com/watch?v=ECukMmdcouY" data-original-link="https://www.youtube.com/watch?v=ECukMmdcouY">周四，Hubert0987 以 4 分 44 秒的成绩</a>打破了世界纪录，在几个小时内，DemonSlayer6669 似乎就以快了 18 秒的成绩获得了吹嘘的资本，这或许是<a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:7;pos:1" class="no-affiliate-link" href="https://www.youtube.com/watch?v=QISs1zuuVBk" data-original-link="https://www.youtube.com/watch?v=QISs1zuuVBk">第一个有记录的 4 分 30 秒以下的成绩</a>。 （如果您还没有通关游戏并且想避免剧透，请不要观看视频。） </p><div id="8a4c5f1cc45a4efb88fda3d7bdceee79"><iframe src="https://www.youtube.com/embed/QISs1zuuVBk?rel=0" style="top:0;left:0;width:100%;height:100%;position:absolute;border:0;" allowfullscreen scrolling="no" data-embed-domain="www.youtube.com"></iframe></div><p> <em>《Animal Well》</em>上线还不到一周，所以随着跑者优化通往游戏最后冲刺的路线，你可以预期记录会不断刷新。很高兴看到围绕一款新游戏形成了一个速通社区，熟练的玩家们正在一决高下，也许是为了有机会在下一场大型<a data-i13n="cpos:8;pos:1" href="https://www.engadget.com/tag/games-done-quick/">Games Done Quick 活动</a>中展示他们的技能。</p>本文最初发表在 Engadget 上，网址为 https://www.engadget.com/animal-well-speedrunners-are-already-beating-the-game-in-under- Five-minutes-195259598.html?src=rss]] >; </description><link/><![CDATA[https://www.engadget.com/animal-well-speedrunners-are-already-beating-the-game-in-under-five-minutes-195259598.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> 1d034ba3-9448-4189-8b8e-bd7526620d41 </guid><dc:creator><![CDATA[Kris Holt]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 19:53:01 +0000</pubDate><ingested> 1715716396</ingested><modified> 2024-05-14T19:53:19+00:00 </modified><category><![CDATA[Sports & Recreation]]></category><category><![CDATA[Consumer Discretionary]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Kris Holt]]></category><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2F7a590c30-1229-11ef-ba9f-d9106e80db20&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=fe11469f418bd9411929a672903a72c3ac894028" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2F7a590c30-1229-11ef-ba9f-d9106e80db20&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=199da26ee1a7f29ee74ff546f24785512622df8b" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[Billy Basso/Bigmode]]></media:credit><media:description><![CDATA[Animal Well]]></media:description><media:title><![CDATA[Animal Well]]></media:title></media:content></item><item><title><![CDATA[Google expands digital watermarks to AI-made video and text]]></title><description type="html"><![CDATA[<p>随着谷歌开始提供最新的视频生成工具，该公司<a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1" class="no-affiliate-link" href="https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/" data-original-link="https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/">表示，它有一项计划</a>，以确保其日益逼真的人工智能生成剪辑的来源透明。得益于 Google 的 SynthID 系统，VideoFX 应用程序中该公司新 Veo 模型制作的所有视频都将带有数字水印。此外，SynthID 将能够为来自 Gemini 的人工智能生成文本添加水印。</p><p> SynthID 是谷歌的<a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1" class="no-affiliate-link" href="https://deepmind.google/technologies/synthid/" data-original-link="https://deepmind.google/technologies/synthid/">数字水印</a>系统， <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1" class="no-affiliate-link" href="https://www.engadget.com/google-wants-an-invisible-digital-watermark-to-bring-transparency-to-ai-art-164551794.html" data-original-link="https://www.engadget.com/google-wants-an-invisible-digital-watermark-to-bring-transparency-to-ai-art-164551794.html">去年</a>开始推出人工智能生成的图像。该技术将难以察觉的水印嵌入到人工智能制作的内容中，以便人工智能检测工具可以识别出该内容是由人工智能生成的。考虑到该公司在 I/O 舞台上预览的最新视频生成模型 Veo 可以创建比以前更长、更高分辨率的剪辑，因此跟踪此类内容的来源将变得越来越重要。</p><span id="end-legacy-contents"></span><p>随着生成式人工智能模型的进步，由于担心人工智能可能助长新一波的错误信息，越来越多的公司开始转向水印。水印系统将为谷歌等平台提供一个框架，用于检测人工智能生成的内容，否则这些内容可能无法区分。 <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1" class="no-affiliate-link" href="https://www.engadget.com/tiktok-will-automatically-label-more-ai-generated-content-in-its-app-120001090.html" data-original-link="https://www.engadget.com/tiktok-will-automatically-label-more-ai-generated-content-in-its-app-120001090.html">TikTok</a>和<a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1" class="no-affiliate-link" href="https://www.engadget.com/meta-plans-to-more-broadly-label-ai-generated-content-152945787.html" data-original-link="https://www.engadget.com/meta-plans-to-more-broadly-label-ai-generated-content-152945787.html">Meta</a>最近还宣布计划在其平台上支持类似的检测工具，并在其应用程序中标记更多人工智能内容。</p><p>当然，数字水印本身是否能提供足够的保护以防止欺骗性人工智能内容仍然存在<a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:6;pos:1" class="no-affiliate-link" href="https://www.engadget.com/can-digital-watermarking-protect-us-from-generative-ai-184542396.html" data-original-link="https://www.engadget.com/can-digital-watermarking-protect-us-from-generative-ai-184542396.html">重大问题</a>。研究人员已经证明水印很容易被<a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:7;pos:1" class="no-affiliate-link" href="https://www.engadget.com/researchers-say-current-ai-watermarks-are-trivial-to-remove-204414059.html" data-original-link="https://www.engadget.com/researchers-say-current-ai-watermarks-are-trivial-to-remove-204414059.html">规避</a>。但以某种方式检测人工智能制作的内容是迈向透明度的重要的第一步。</p><p>在<a data-i13n="cpos:8;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p>本文最初发表在 Engadget 上：https://www.engadget.com/google-expands-digital-watermarks-to-ai-made-video-175232320.html?src=rss]]>; </description><link/><![CDATA[https://www.engadget.com/google-expands-digital-watermarks-to-ai-made-video-175232320.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> 049c53a2-f09b-4710-bc63-ecc8759a3778 </guid><dc:creator><![CDATA[Karissa Bell]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 18:55:39 +0000</pubDate><ingested> 1715712939</ingested><modified> 2024-05-14T18:55:49+00:00 </modified><category><![CDATA[Software]]></category><category><![CDATA[Technology & Electronics]]></category><category><![CDATA[Information Technology]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Karissa Bell]]></category><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2F0c65a230-1222-11ef-bbff-6d2ec36e6db2&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=d045d39e227bba33c39499630602c38c6310054f" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2F0c65a230-1222-11ef-bbff-6d2ec36e6db2&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=aa416be466b4b6fce2c8c43e5bbccd46496056f5" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[Google SynthID updates]]></media:description><media:title><![CDATA[Google SynthID updates]]></media:title></media:content></item><item><title><![CDATA[Gemini will be accessible in the side panel on Google apps like Gmail and Docs]]></title><description type="html"><![CDATA[<p>谷歌正在将 Gemini 支持的人工智能自动化<a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1" class="no-affiliate-link" href="https://workspace.google.com/blog/product-announcements/new-ways-engage-gemini-workspace" data-original-link="https://workspace.google.com/blog/product-announcements/new-ways-engage-gemini-workspace">添加</a>到 Workspace 中的更多任务中。在周二的 Google I/O 主题演讲中，该公司表示，随着人工智能变得更加智能，了解更多信息，其先进的<a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/googles-gemini-15-pro-is-a-new-more-efficient-ai-model-181909354.html">Gemini 1.5 Pro</a>将很快在 Workspace 侧面板中提供，作为“具有人工智能驱动的工作流程的跨多个应用程序的结缔组织”您并自动化更多的工作流程。</p><p> Gemini 在 Workspace 中的作用是节省您从多个应用程序中挖掘文件、电子邮件和其他数据的时间和精力。 Google Workspace 副总裁 Aparna Pappu 在活动中表示：“Gemini 时代的 Workspace 将继续开启完成工作的新方式。”</p><span id="end-legacy-contents"></span><p>更新后的工作区侧面板首先出现在 Gmail、文档、表格、幻灯片和云端硬盘中，让您可以与 Gemini 讨论您的内容。其较长的上下文窗口（本质上是其内存）使其能够组织、理解来自不同应用程序的数据并将其置于上下文中，而无需离开您所在的应用程序。这包括比较收据附件、总结（以及回答来回问题）关于）长电子邮件线程，或突出会议录音中的要点。 </p><figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/b21f79d0-1222-11ef-8fdf-5be87f61ee11" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/b21f79d0-1222-11ef-8fdf-5be87f61ee11" style="height:720px;width:1280px;" alt="工作区幻灯片" data-uuid="3892b82e-5694-36f5-b4ee-6e6f2f1220ee"><figcaption></figcaption><div class="photo-credit">谷歌</div></figure><p>谷歌提供的另一个例子是，当你的祖母询问酒店信息时，你正在计划一次家庭聚会。通过 Workspace 侧面板，您可以使用提示“@Family Reunion 2024 中列出的酒店名称和销售经理电子邮件是什么？”来要求 Gemini 查找包含预订信息的 Google 文档。谷歌表示，它将找到该文件并给你一个快速答案，允许你将其插入你的回复中，因为你可以通过为可怜的奶奶伪造人类真实性来节省时间。</p><p>基于电子邮件的更改也将出现在 Gmail 移动应用中。该公司表示：“Gemini 很快就能分析电子邮件线索，并直接在 Gmail 应用程序中提供包含主要亮点的摘要视图，就像在侧面板中一样。”</p><p> Gmail 应用程序中的摘要将于本月登陆 Workspace Labs。与此同时，升级后的 Workspace 侧面板将于周二开始为 Workspace Labs 和 Workspace Alpha 用户提供 Gemini。谷歌表示，所有功能将于下个月向其他 Workspace 客户和 Google One AI Premium 用户提供。</p><p>在<a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p><p></p>本文最初发表在 Engadget 上：https://www.engadget.com/gemini-will-be-accessible-in-the-side-panel-on-google-apps-like-gmail-and-docs-185406695.html ?src=rss]]>; </description><link/><![CDATA[https://www.engadget.com/gemini-will-be-accessible-in-the-side-panel-on-google-apps-like-gmail-and-docs-185406695.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> 186f2c48-090e-457a-ac44-104a9eddc0d3</guid><dc:creator><![CDATA[Will Shanklin]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 18:54:07 +0000</pubDate><ingested> 1715712848</ingested><modified> 2024-05-14T18:54:21+00:00 </modified><category><![CDATA[Software]]></category><category><![CDATA[Technology & Electronics]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Will Shanklin]]></category><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2Fe30856d0-1221-11ef-b4fb-90662859d445&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=e8b20744a61e6a2642ebd569b2e0c558092a5c21" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2Fe30856d0-1221-11ef-b4fb-90662859d445&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=4c2a16ca811611e0aad67a5326b7133b052448f5" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[Google]]></media:credit><media:description><![CDATA[Google's Aparna Pappu onstage with a "Gemini for Workspace" slide behind her.]]></media:description><media:title><![CDATA[Gemini for Workspace]]></media:title></media:content></item><item><title><![CDATA[Google Gemini can power a virtual AI teammate with its own Workspace account]]></title><description type="html"><![CDATA[<p>从<a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-the-latest-on-gemini-ai-android-15-and-more-110008373.html">今天的 I/O 主题演讲</a>来看，谷歌的<a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/googles-new-gemini-15-flash-ai-model-is-lighter-than-gemini-pro-and-more-accessible-172353657.html">Gemini AI</a>系统可以做很多事情。其中包括使用自己的工作区帐户设置虚拟队友的选项。您可以配置团队成员执行特定任务，例如监控和跟踪项目、组织信息、提供上下文、分析数据后查明趋势以及在团队协作中发挥作用。</p><p>在 Google Chat 中，队友可以加入所有相关房间，您可以根据所有对话历史记录、Gmail 线程以及它有权访问的任何其他内容向其提问。它可以告诉团队成员他们的项目是否获得批准，或者是否存在基于冲突消息的问题。</p><span id="end-legacy-contents"></span><p>然而，虚拟队友目前似乎只是一个技术演示。 Workspace 副总裁兼总经理 Aparna Pappu 表示，谷歌“还有很多工作要做，才能弄清楚如何将虚拟队友等代理体验引入 Workspace。”这包括寻找方法让第三方制作自己的版本。</p><p>虽然这个虚拟队友似乎不会很快推出，但它最终可能会节省大量时间——只要你相信它第一次就能把一切做好。</p><p>在<a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p>本文最初发表在 Engadget 上：https://www.engadget.com/google-gemini-can-power-a-virtual-ai-teammate-with-its-own-workspace-account-182809274.html?src=rss ]]>; </description><link/><![CDATA[https://www.engadget.com/google-gemini-can-power-a-virtual-ai-teammate-with-its-own-workspace-account-182809274.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> 61ee29e4-16a6-424f-852b-ab8401894266 </guid><dc:creator><![CDATA[Kris Holt]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 18:28:09 +0000</pubDate><ingested> 1715711290</ingested><modified> 2024-05-14T18:28:18+00:00 </modified><category><![CDATA[Technology & Electronics]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Kris Holt]]></category><media:content height="845" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2Fc168bb80-121e-11ef-bfdb-43e1d1c8b5b8&amp;resize=1400%2C845&amp;client=19f2b5e49a271b2bde77&amp;signature=7997936b49d1e89cdf75f180951a5203bb2e4d62" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="845" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2Fc168bb80-121e-11ef-bfdb-43e1d1c8b5b8&amp;resize=1400%2C845&amp;client=19f2b5e49a271b2bde77&amp;signature=26842ad3428557c6ca7e6d22529a8638c7e170f1" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[Google]]></media:credit><media:description><![CDATA[Google I/O]]></media:description><media:title><![CDATA[Google I/O]]></media:title></media:content></item><item><title><![CDATA[Google announces new scam detection tools that provide real-time alerts during phone calls]]></title><description type="html"><![CDATA[<p>谷歌刚刚宣布将于今年晚些时候在 Android 手机上<a data-i13n="cpos:1;pos:1" href="https://blog.google/products/android/google-ai-android-update-io-2024/">推出诈骗检测工具</a>，这是一件好事，因为这些诈骗者在<a data-i13n="cpos:2;pos:1" href="https://www.newswire.com/news/global-losses-to-scammers-exceed-1-trillion-as-1-in-4-lose-money-to-22145725">骗取人们的钱财方面</a>越来越擅长。该工具集在 Google I/O 2024 上发布，仍处于测试阶段，但使用人工智能在对话中识别欺诈者。</p><p>你没看错。人工智能将不断寻找与诈骗相关的对话模式。一旦检测到，您将在电话上收到实时警报，消除对另一端的人实际上<a data-i13n="cpos:3;pos:1" href="https://spectrumlocalnews.com/nc/charlotte/news/2023/07/24/scammers-disguised-as-process-servers-target-personal-info">正在发送法庭传票</a>或其他任何东西的担忧。</p><span id="end-legacy-contents"></span><p>谷歌举了一个“银行代表”要求提供个人信息（例如 PIN 码和密码）的例子。这些是不常见的银行请求，因此人工智能会标记它们并发出警报。一切都发生在设备上，因此它保持私密性。该功能不会立即出现在 Android 15 中，该公司表示将在今年晚些时候分享更多细节。我们确实知道人们必须选择使用该工具。</p><p>谷歌在 Android 15 上迈出了一大步，将其 Gemini 聊天机器人引入实际设备，而不需要连接到云端。除了这种诈骗检测技术之外，板载人工智能的添加将允许更多功能，例如使用应用程序时的上下文感知。</p><p>在<a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p><p></p>本文最初发表在 Engadget 上，网址为 https://www.engadget.com/google-announces-new-scam-detection-tools-that-provide-real-time-alerts-during-phone-calls-181442091.html?src =rss]]>; </description><link/><![CDATA[https://www.engadget.com/google-announces-new-scam-detection-tools-that-provide-real-time-alerts-during-phone-calls-181442091.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> fa87e71b-ef60-466d-ac8a-914b8c669907</guid><dc:creator><![CDATA[Lawrence Bonk]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 18:14:42 +0000</pubDate><ingested> 1715711572</ingested><modified> 2024-05-14T18:32:57+00:00 </modified><category><![CDATA[Software]]></category><category><![CDATA[Technology & Electronics]]></category><category><![CDATA[Small Businesses]]></category><category><![CDATA[Personal Investing Ideas & Strategies]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Lawrence Bonk]]></category><media:content height="784" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2F331f7dd0-1220-11ef-993f-dce467d2875a&amp;resize=1400%2C784&amp;client=19f2b5e49a271b2bde77&amp;signature=530001189c17bdc7cf458a51c3326e84fba2cb42" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="784" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2F331f7dd0-1220-11ef-993f-dce467d2875a&amp;resize=1400%2C784&amp;client=19f2b5e49a271b2bde77&amp;signature=22bc90ef5238dfcda4e886096a19205ca0556f7f" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[Google]]></media:credit><media:description><![CDATA[Scam tool in use.]]></media:description><media:title><![CDATA[Android Scam]]></media:title></media:content></item><item><title><![CDATA[With Gemini Live, Google wants you to relax and have a natural chat with AI]]></title><description type="html"><![CDATA[<p>尽管谷歌和 OpenAI 在过去的一年里一直在争夺人工智能桂冠，但我们似乎已经放弃了与虚拟助手对话的想法。生成式人工智能产品通常只提供文本输入，后来才添加搜索图像和基本语音命令的功能。在今天的 Google I/O 大会上，该公司展示了 Gemini Live，这是一种与其 AI 进行自然对话的新移动体验。</p><p>谷歌提供了一些潜在的用例；您可以与 Gemini Live 进行对话，以帮助准备工作面试，它可能会询问您有关职位的相关问题。如果您想研究演讲，它还可以为您提供公开演讲技巧。 Gemini Live 的独特之处在于，您可以按照自己的节奏说话，甚至可以根据需要打断其响应。理想情况下，它应该更像是与人交谈，而不仅仅是发出智能助理命令或生成人工智能查询。 </p><span id="end-legacy-contents"></span><div id="531f92aeea504fccad469eea050e0cdc"><div style="left:0;width:100%;height:0;position:relative;padding-bottom:56.25%;"><iframe src="https://www.youtube.com/embed/nXVvvRhiGjI?rel=0" style="top:0;left:0;width:100%;height:100%;position:absolute;border:0;" allowfullscreen="" scrolling="no" data-embed-domain="www.youtube.com"></iframe></div></div><p>在 I/O 大会上， <a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/googles-project-astra-uses-your-phones-camera-and-ai-to-find-noise-makers-misplaced-items-and-more-172642329.html">谷歌还展示了 Project Astra</a> ，这是一款下一代虚拟助手，进一步深化了 Gemini Live 的概念。 Astra 能够查看您的摄像头并实时回答问题。目前尚不清楚这需要多长时间才能实现，但谷歌表示，Astra 的一些实时视频功能将于今年晚些时候登陆 Gemini Live。 Gemini Live 将在未来几个月内向 Gemini Advanced 订阅者开放。</p><p>在<a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p><p></p>本文最初发表在 Engadget 上：https://www.engadget.com/with-gemini-live-google-wants-you-to-relax-and-have-a-natural-chat-with-ai-181329788.html ?src=rss]]>; </description><link/><![CDATA[https://www.engadget.com/with-gemini-live-google-wants-you-to-relax-and-have-a-natural-chat-with-ai-181329788.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> 5f3da33f-3fa3-40b1-9b27-b418d627674b </guid><dc:creator><![CDATA[Devindra Hardawar]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 18:13:29 +0000</pubDate><ingested> 1715711662</ingested><modified> 2024-05-14T18:34:25+00:00 </modified><category><![CDATA[Social & Online Media]]></category><category><![CDATA[Personal Investing Ideas & Strategies]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Devindra Hardawar]]></category><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2F6df74d50-121d-11ef-bf77-5a09f84442d2&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=1d936085831429a52ee14ff83feaa5f03b747144" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2F6df74d50-121d-11ef-bf77-5a09f84442d2&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=76e6f49fc6b4185895b20dc8c7b218cb2332c52a" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[Google]]></media:credit><media:description><![CDATA[Gemini Live]]></media:description><media:title><![CDATA[Gemini Live]]></media:title></media:content></item><item><title><![CDATA[Google's Gemini Nano brings better image-description smarts to its TalkBack vision tool]]></title><description type="html"><![CDATA[<p> Google I/O 活动即将到来，该公司宣布<a data-i13n="cpos:1;pos:1" href="https://blog.google/products/android/google-ai-android-update-io-2024/">为您的 Android 设备带来许多重大更新</a>。正如我们之前听说的，Gemini Nano 正在获得多模式支持，这意味着您的 Android 仍将处理文本，但可以更好地理解其他因素，如视觉、声音和口语。现在，谷歌宣布新工具也将加入其 TalkBack 功能。</p><p> <a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/googles-latest-android-update-includes-ai-created-image-descriptions-and-animations-for-voice-messages-172522129.html">TalkBack</a>是一种现有的工具，可以大声朗读图像的描述，无论该图像是您捕获的图像还是来自互联网的图像。 Gemini Nano 的多模式支持应该可以提供对图像更详细的理解。据 Google 称，TalkBack 用户每天都会遇到大约 90 张没有标签的图像。 Gemini Nano 应该能够提供缺失的信息，例如一件衣服的样子或朋友发送的新照片的详细信息。</p><span id="end-legacy-contents"></span><p> <a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/googles-gemini-ai-is-coming-to-android-150025984.html">Gemini Nano</a>直接在人的设备上工作，这意味着它在没有任何网络连接的情况下仍然可以正常运行。虽然我们还没有确切的发布日期，但谷歌表示 TalkBack 将在今年晚些时候获得 Gemini Nano 的更新功能。</p><p>在<a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p>本文最初发表在 Engadget 上：https://www.engadget.com/googles-gemini-nano-brings-better-image-description-smarts-to-its-talkback-vision-tool-180759598.html?src=rss ]]>; </description><link/><![CDATA[https://www.engadget.com/googles-gemini-nano-brings-better-image-description-smarts-to-its-talkback-vision-tool-180759598.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> 3f872cf6-4db7-4a91-a270-500084f3bde6 </guid><dc:creator><![CDATA[Sarah Fielding]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 18:07:59 +0000</pubDate><ingested> 1715710079</ingested><modified> 2024-05-14T18:08:12+00:00 </modified><category><![CDATA[Technology & Electronics]]></category><category><![CDATA[Small Businesses]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Sarah Fielding]]></category><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2F107fa5a0-11d2-11ef-b7bd-7dbab4f8d9bc&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=be7acd5333fa28cf4322875204466828f086c620" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="787" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2F107fa5a0-11d2-11ef-b7bd-7dbab4f8d9bc&amp;resize=1400%2C787&amp;client=19f2b5e49a271b2bde77&amp;signature=ecc6bf35dd8c1c7929efae93efe45a70f2a02636" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[Google]]></media:credit><media:description><![CDATA[A dress is shown on screen with a description of it.]]></media:description><media:title><![CDATA[Description with TalkBack of a dress]]></media:title></media:content></item><item><title><![CDATA[Google builds Gemini right into Android, adding contextual awareness within apps]]></title><description type="html"><![CDATA[<p>作为该<a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/how-to-watch-googles-io-2024-keynote-160010787.html">公司 I/O 2024 活动的</a>一部分，谷歌刚刚宣布对其适用于 Android 设备的 Gemini AI 聊天机器人<a data-i13n="cpos:1;pos:1" href="https://blog.google/products/android/google-ai-android-update-io-2024/">进行一些巧妙的改进</a>。人工智能现已成为 Android 操作系统的一部分，使其能够以更全面的方式集成。</p><p>如果没有与底层操作系统的集成，最酷的新功能就不可能实现。当您控制智能手机上的应用程序时，双子座现在可以更好地理解上下文。这究竟意味着什么？一旦该工具作为 Android 15 的一部分正式启动，您将能够在您正在使用的应用程序之上调出 Gemini 覆盖层。这将允许特定于上下文的操作和查询。</p><span id="end-legacy-contents"></span><p> Google 给出了快速将生成的图像放入 Gmail 和 Google Messages 中的示例，尽管您<a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/google-pauses-geminis-ability-to-generate-people-after-overcorrecting-for-diversity-in-historical-images-220303074.html">现在可能希望避开历史图像</a>。该公司还推出了一项名为“询问此视频”的功能，让用户可以针对特定的 YouTube 视频提出问题，聊天机器人应该能够回答这些问题。谷歌表示，这应该适用于“数十亿”的视频。还有一个类似的 PDF 工具。 </p><figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/9a242180-121f-11ef-9fff-6948a55657c2" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/9a242180-121f-11ef-9fff-6948a55657c2" style="height:960px;width:1700px;" alt="使用 YouTube。" data-uuid="bc956670-146c-3606-8f7d-415b3ceb6945"><figcaption></figcaption><div class="photo-credit">谷歌</div></figure><p>很容易看出这项技术的发展方向。一旦 Gemini 能够访问您的应用程序库的大部分，它应该能够真正兑现 Humane 和<a data-i13n="cpos:5;pos:1" href="https://www.engadget.com/rabbit-r1-review-a-199-ai-toy-that-fails-at-almost-everything-161043050.html">Rabbit</a> <a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/the-humane-ai-pin-is-the-solution-to-none-of-technologys-problems-120002469.html">等人工智能竞争对手</a>做出的一些崇高承诺。谷歌表示，它“刚刚开始研究设备上的人工智能如何改变你的手机的功能”，因此我们想象未来至少会与 Uber 和 Doordash 等应用程序集成。</p><p>由于机载人工智能，Circle to Search 也得到了提升。用户将能够圈出手机上的几乎所有内容并接收相关信息。谷歌表示，人们无需切换应用程序即可做到这一点。这甚至延伸到数学和物理问题，只是圈出答案，这可能会让学生高兴而让老师感到沮丧。</p><p>在<a data-i13n="cpos:6;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p><p></p>本文最初发表在 Engadget 上：https://www.engadget.com/google-builds-gemini-right-into-android-adding-contextual-awareness-within-apps-180413356.html?src=rss]]>; </description><link/><![CDATA[https://www.engadget.com/google-builds-gemini-right-into-android-adding-contextual-awareness-within-apps-180413356.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> 32f11a48-235a-4c8b-8021-6edbe3fc46bd</guid><dc:creator><![CDATA[Lawrence Bonk]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 18:04:13 +0000</pubDate><ingested> 1715711594</ingested><modified> 2024-05-14T18:33:18+00:00 </modified><category><![CDATA[Software]]></category><category><![CDATA[Mobile Apps]]></category><category><![CDATA[Technology & Electronics]]></category><category><![CDATA[Information Technology]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Lawrence Bonk]]></category><media:content height="706" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2F93fdf3a0-121d-11ef-9ff6-4dcd40725ac2&amp;resize=1400%2C706&amp;client=19f2b5e49a271b2bde77&amp;signature=5f82a61824a62ee3f8ea964ad9435ede374bde45" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="706" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2F93fdf3a0-121d-11ef-9ff6-4dcd40725ac2&amp;resize=1400%2C706&amp;client=19f2b5e49a271b2bde77&amp;signature=adedc8d3240bfc8bba5a58a0aaaf8bc271ed72a6" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[Google]]></media:credit><media:description><![CDATA[Gemini for Android.]]></media:description><media:title><![CDATA[Google Gemini]]></media:title></media:content></item><item><title><![CDATA[Android's Circle to Search can now help students solve math and physics homework]]></title><description type="html"><![CDATA[<p>谷歌在该公司的年度 I/O 开发者大会上推出了<a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/googles-circle-to-search-feature-will-soon-handle-language-translation-174802558.html">另一项“</a> Circle to Search”功能，它可以帮助学生<a data-i13n="cpos:2;pos:1" href="https://blog.google/products/android/google-ai-android-update-io-2024">更好地理解潜在的困难课堂主题</a>。该功能现在将能够向他们展示“一系列物理和数学应用题”的分步说明。他们只需长按主页按钮或导航栏，然后圈出让他们感到困惑的问题即可激活该功能，尽管有些数学问题需要用户注册谷歌的实验性搜索实验室功能。</p><p>该公司表示，Circle to Search 的新功能是通过其名为 LearnLM 的新人工智能模型家族实现的，该模型是专门为学习而创建和微调的。它还计划对这一特定功能进行调整，并在今年晚些时候推出升级版本，可以解决更复杂的问题，“涉及符号公式、图表等”。谷歌今年早些时候在三星 Unpacked 活动中<a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/galaxy-s24-and-pixel-8-owners-can-soon-search-for-anything-by-drawing-a-circle-around-it-180029757.html">推出了 Circle to Search</a> ，因为该功能最初在 Galaxy 24 和 Pixel 8 设备上可用。它现在也适用于 Galaxy S23、Galaxy S22、Z Fold、Z Flip、Pixel 6 和 Pixel 7 设备，并且未来可能会应用于更多硬件。</p><span id="end-legacy-contents"></span><p>除了新的 Circle to Search 功能外，谷歌还透露，支持 Android 聊天机器人助手 Gemini 的设备现在可以将其作为覆盖层显示在当前打开的应用程序之上。然后，用户可以将图像直接从叠加层拖放到 Gmail 等应用程序中，或者使用叠加层查找信息，而无需从他们正在做的事情上滑开。他们可以点击“询问此视频”以在打开的 YouTube 视频中查找特定信息，如果他们有权访问 Gemini Advanced，则可以使用“询问此 PDF”选项从冗长的文档中查找信息。</p><p>谷歌还向 Nano 推出了多模式功能，Nano 是 Gemini 系列中最小的型号，可以在设备上处理信息。更新后的 Gemini Nano 将能够处理视觉、声音和口语，将于今年晚些时候出现在 Google 的 TalkBack 屏幕阅读器中。 Gemini Nano 将使 TalkBack 能够更快地描述屏幕上的图像，甚至在没有互联网连接的情况下也是如此。最后，谷歌目前正在测试 Gemini Nano 功能，如果检测到与诈骗相关的常见对话模式，该功能可以在通话过程中向用户发出警报。例如，如果用户正在与要求他们提供 PIN 或密码的人交谈，或者与要求他们购买礼品卡的人交谈，则会收到警报。</p><p>在<a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p>本文最初发表在 Engadget 上：https://www.engadget.com/androids-circle-to-search-can-now-help-students-solve-math-and-physicals-homework-180223229.html?src=rss ]]>; </description><link/><![CDATA[https://www.engadget.com/androids-circle-to-search-can-now-help-students-solve-math-and-physics-homework-180223229.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> 85d9d7dd-f8c7-4317-a50a-5f7319394d06</guid><dc:creator><![CDATA[Mariella Moon]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 18:02:23 +0000</pubDate><ingested> 1715709744</ingested><modified> 2024-05-14T18:02:36+00:00 </modified><category><![CDATA[Technology & Electronics]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Mariella Moon]]></category><media:content height="889" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2Fa60abd90-11d6-11ef-bfe1-78dcd8ffbe7c&amp;resize=1400%2C889&amp;client=19f2b5e49a271b2bde77&amp;signature=7243f9263f1c4c0f53390b9cdc04329b9b6ee0eb" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="889" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2Fa60abd90-11d6-11ef-bfe1-78dcd8ffbe7c&amp;resize=1400%2C889&amp;client=19f2b5e49a271b2bde77&amp;signature=2baf8de57e04c36f248dbb743310c32a57d11538" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[Google]]></media:credit><media:description><![CDATA[Android circle to search feature.]]></media:description><media:title><![CDATA[Android circle to search]]></media:title></media:content></item><item><title><![CDATA[Google's Gemini will search your videos to help you solve problems]]></title><description type="html"><![CDATA[<p>作为推动将生成式人工智能添加到搜索中的一部分，谷歌引入了一个新的转折点：视频。 Gemini 会让您上传演示您要解决的问题的视频，然后搜索用户论坛和互联网的其他区域以找到解决方案。</p><p>举个例子，Google 的 Rose Yao 在 I/O 2024 的舞台上谈到了她购买的二手转盘以及她如何无法将唱针固定在唱片上。 Yao 上传了一段显示该问题的视频，然后 Gemini 很快找到了一个解释者，描述了如何在特定品牌和型号上平衡手臂。 </p><span id="end-legacy-contents"></span><figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/7c7a9110-1183-11ef-ab8f-70abbde0846d" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/7c7a9110-1183-11ef-ab8f-70abbde0846d" style="height:1000px;width:1000px;" alt="谷歌的 Gemini 现在搜索视频来回答你的问题" data-uuid="e2a63ebf-db5c-3f12-b76f-0419bb7cfc9c"><figcaption></figcaption><div class="photo-credit">谷歌</div></figure><p>谷歌写道：“搜索不仅仅是文本框中的文字。你遇到的问题通常是关于你周围看到的事物，包括运动的物体。” “通过视频进行搜索可以节省您寻找正确词语来描述此问题的时间和麻烦，并且您将获得包含故障排除步骤和资源的 AI 概述。”</p><p>如果视频本身无法清楚地说明您想要弄清楚的内容，您可以添加文本或绘制指向相关问题的箭头。</p><p> OpenAI <a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/openai-claims-that-its-free-gpt-4o-model-can-talk-laugh-sing-and-see-like-a-human-184249780.html">刚刚推出了 ChatGPT 4o</a> ，它能够实时解释实时视频，然后描述一个场景，甚至唱一首与之相关的歌曲。然而，谷歌在视频方面采取了不同的策略，目前专注于其搜索产品。该公司表示，美国搜索实验室用户首先可以使用英语进行视频搜索，但随着时间的推移，将扩展到更多地区。</p><p>在<a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p>本文最初发表在 Engadget 上：https://www.engadget.com/googles-gemini-will-search-your-videos-to-help-you-solve-problems-175235105.html?src=rss]]>; </description><link/><![CDATA[https://www.engadget.com/googles-gemini-will-search-your-videos-to-help-you-solve-problems-175235105.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> 64f4e9e3-35cd-4ad5-9cc3-d0ff75ffc5f9 </guid><dc:creator><![CDATA[Steve Dent]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 17:52:35 +0000</pubDate><ingested> 1715709156</ingested><modified> 2024-05-14T17:52:44+00:00 </modified><category><![CDATA[Technology & Electronics]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Steve Dent]]></category><media:content height="994" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2F15423330-1184-11ef-a0ff-9574304716fb&amp;resize=1400%2C994&amp;client=19f2b5e49a271b2bde77&amp;signature=2690fc0af2c66e8b0aa2f2342d5c2230e795dfe6" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="994" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2Fe7e15230-1189-11ef-beff-019ee3a658ed&amp;resize=1400%2C994&amp;client=19f2b5e49a271b2bde77&amp;signature=cbd3140f4f88893ff730d1aea2074733e51c40cc" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[Google]]></media:credit><media:description><![CDATA[Google's Gemini will search video to answer your questions]]></media:description><media:title><![CDATA[Google's Gemini will search video to answer your questions]]></media:title></media:content></item><item><title><![CDATA[Google Search will now show AI-generated answers to millions by default]]></title><description type="html"><![CDATA[<p>谷歌正在改变搜索。周二，该公司在谷歌开发者年度大会 I/O 上宣布了对全球主导搜索引擎进行人工智能驱动的重大变革。凭借这些新功能，谷歌将搜索定位为不仅仅是一种简单地查找网站的方式。相反，该公司希望人们使用其搜索引擎直接获得答案，并帮助他们规划活动和集思广益。</p><p>谷歌搜索副总裁兼负责人 Liz Reid 在一篇<a data-i13n="cpos:1;pos:1" href="https://blog.google/products/search/generative-ai-google-search-may-2024">博客文章</a>中写道：“借助生成式人工智能，搜索可以做的事情比你想象的还要多。” “所以你可以提出任何你想到的事情或任何你需要完成的事情——从研究到计划再到集思广益——谷歌将负责所有的跑腿工作。”</p><span id="end-legacy-contents"></span><p>谷歌对搜索（该公司赚钱的主要方式）的改变是对自 2022 年底 OpenAI 的 ChatGPT 发布以来生成式人工智能爆炸式增长的回应。从那时起，包括 ChatGPT、Anthropic 在内的一些人工智能驱动的应用程序和服务出现了。 、Perplexity 和由 OpenAI 的 GPT-4 提供支持的微软 Bing 通过直接提供问题答案而不是简单地向人们提供链接列表来挑战谷歌的旗舰服务。这就是谷歌正在竞相通过其搜索新功能来弥补的差距。</p><p>从今天开始，谷歌将在美国结果页面的顶部显示人工智能生成的完整答案，以响应大多数搜索查询。谷歌在一年前的 2023 年 Google I/O 大会上<a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/google-search-generative-experience-preview-a-familiar-yet-different-approach-175156245.html?_fsig=Jq96xGV4zAtGSgsHELLUaA--~A">首次推出了</a>该功能，但到目前为止，任何想要使用该功能的人都必须注册该功能，作为该公司<a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/google-will-start-showing-ai-powered-search-results-to-users-who-didnt-opt-in-093036257.html">搜索实验室</a>平台的一部分，该平台允许人们在发布之前试用即将推出的功能。他们的普遍释放。谷歌目前正在向数亿美国人提供人工智能概述，并表示预计到今年年底将在更多国家向超过 10 亿人提供该服务。里德写道，选择通过搜索实验室尝试该功能的人到目前为止已经使用了“数十亿次”，并表示，作为人工智能生成的答案的一部分包含的任何链接都会比该页面作为传统页面出现时获得更多的点击次数。网络列表，这是出版商一直关心的问题。 “随着我们扩展这种体验，我们将继续专注于向出版商和创作者发送有价值的流量，”里德写道。</p><p>除了人工智能概述之外，在美国用英语搜索有关餐饮和食谱的某些查询，以及随后搜索电影、音乐、书籍、酒店、购物等内容，将显示一个新的搜索页面，其中使用人工智能来组织结果。 “当你在寻找想法时，搜索将使用生成人工智能与你进行头脑风暴，并创建一个人工智能组织的结果页面，使探索变得容易，”里德在博客文章中说。 </p><p></p><figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/87302290-11bb-11ef-befd-63da25cb3455" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/87302290-11bb-11ef-befd-63da25cb3455" style="height:750px;width:750px;" alt="AI 组织结果页面" data-uuid="b13c1389-8ba8-3ec8-936d-24bdc45089a5"><figcaption></figcaption><div class="photo-credit">谷歌</div></figure><p></p><p>如果您选择加入搜索实验室，您将能够在 Google 搜索中使用由生成式 AI 提供支持的更多功能。您将能够获得人工智能概述来简化语言或更详细地分解复杂的主题。这是一个要求 Google 解释的查询示例，例如闪电和雷声之间的联系。 </p><figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/3d6fac20-11bb-11ef-87bd-16f612799e13" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/3d6fac20-11bb-11ef-87bd-16f612799e13" style="height:623px;width:960px;" alt="Google 搜索中的一项新功能可让人们提出复杂的查询" data-uuid="228a9960-758f-38b8-bdec-4fb911275afa"><figcaption></figcaption><div class="photo-credit">谷歌</div></figure><p></p><p></p><p>搜索实验室测试人员还可以在单​​个查询中向 Google 提出非常复杂的问题，以便在单个页面上获得答案，而不必进行多次搜索。谷歌博客文章给出的例子是：“找到波士顿最好的瑜伽或普拉提工作室，并显示他们的介绍优惠和从灯塔山出发的步行时间的详细信息。”作为回应，谷歌展示了波士顿灯塔山附近评价最高的瑜伽和普拉提工作室，甚至将它们放在地图上以便于导航。 </p><figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/b1e29db0-11bb-11ef-bb2c-4726913964d5" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/b1e29db0-11bb-11ef-bb2c-4726913964d5" style="height:750px;width:750px;" alt="灯塔山" data-uuid="69192499-fc9d-30bd-80ee-4063c2e87e51"><figcaption></figcaption><div class="photo-credit">谷歌</div></figure><p>谷歌还希望成为膳食和假期规划者，让注册搜索实验室的人提出诸如“为易于准备的团体创建 3 天膳食计划”之类的问题，并让你在人工智能生成的计划中交换个人结果用其他东西（例如，将膳食计划中的肉类菜肴改为素食菜肴）。 </p><figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/d62cc6f0-11bb-11ef-bdbd-d8fbd6988273" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2024-05/d62cc6f0-11bb-11ef-bdbd-d8fbd6988273" style="height:623px;width:960px;" alt="膳食计划" data-uuid="9933ba94-221e-30c7-936c-373f47fc6595"><figcaption></figcaption><div class="photo-credit">谷歌</div></figure><p>最后，谷歌最终将允许任何注册搜索实验室的人使用视频作为搜索查询，而不是文本或图像。里德在谷歌的博客文章中写道：“也许你在旧货店买了一台电唱机，但当你打开它时，它无法工作，并且带有唱针的金属片会意外地漂移。” “使用视频搜索可以节省您寻找正确词语来描述此问题的时间和麻烦，并且您将获得人工智能概述，其中包含用于排除故障的步骤和资源。”</p><p>谷歌表示，所有这些新功能均由专为搜索定制的全新Gemini模型提供支持，该模型将Gemini先进的多步推理和多模态能力与谷歌的传统搜索系统相结合。</p><p>在<a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/google-io-2024-live-updates-gemini-ai-android-15-and-more-110008966.html"><em>这里</em></a><em>了解 Google I/O 2024 的所有新闻</em><em>！</em></p><p></p>本文最初发表在 Engadget 上，网址为 https://www.engadget.com/google-search-will-now-show-ai- generated-answers-to-millions-by-default-174512845.html?src=rss]] >; </description><link/><![CDATA[https://www.engadget.com/google-search-will-now-show-ai-generated-answers-to-millions-by-default-174512845.html?src=rss]]><source_id> engadget_479</source_id><guid ispermalink="false"> a7131772-8493-46b2-9be4-d53623feb717 </guid><dc:creator><![CDATA[Pranav Dixit]]></dc:creator><source/><![CDATA[Engadget]]><dc:publisher><![CDATA[Engadget]]></dc:publisher><dc:rightsholder><![CDATA[Engadget]]></dc:rightsholder><pubDate> Tue, 14 May 2024 17:45:12 +0000</pubDate><ingested> 1715708713</ingested><modified> 2024-05-14T17:45:30+00:00 </modified><category><![CDATA[Media]]></category><category><![CDATA[Personal Investing Ideas & Strategies]]></category><category><![CDATA[site|engadget]]></category><category><![CDATA[provider_name|Engadget]]></category><category><![CDATA[region|US]]></category><category><![CDATA[language|en-US]]></category><category><![CDATA[author_name|Pranav Dixit]]></category><media:content height="933" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2024-05%2F13a21d50-11bc-11ef-b65e-4c89bb8bc596&amp;resize=1400%2C933&amp;client=19f2b5e49a271b2bde77&amp;signature=474f1e053dba12de828b79a71caf5a032a73b02b" width="1400"><media:keywords>标题</media:keywords><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[1]]></dc:identifier><media:credit><![CDATA[ ]]></media:credit><media:description><![CDATA[ ]]></media:description><media:title><![CDATA[ ]]></media:title></media:content><media:content height="933" medium="image" url="https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fmedia-mbst-pub-ue1.s3.amazonaws.com%2Fcreatr-uploaded-images%2F2024-05%2F13a21d50-11bc-11ef-b65e-4c89bb8bc596&amp;resize=1400%2C933&amp;client=19f2b5e49a271b2bde77&amp;signature=6687d930aa059069bbd42dc687c324e53843a2d6" width="1400"><media:media_html><![CDATA[ ]]></media:media_html><dc:identifier><![CDATA[2]]></dc:identifier><media:credit><![CDATA[SOPA Images via Getty Images]]></media:credit><media:description><![CDATA[BRAZIL - 2024/02/28: In this photo illustration, the Google IO logo is displayed on a smartphone screen. (Photo Illustration by Rafael Henrique/SOPA Images/LightRocket via Getty Images)]]></media:description><media:title><![CDATA[In this photo illustration, the Google IO logo is displayed...]]></media:title></media:content></item></channel></rss>